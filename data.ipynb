{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47f13460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1962, 3488, 3)\n"
     ]
    }
   ],
   "source": [
    "import imageio.v2 as imageio\n",
    "\n",
    "img = imageio.imread('ontario.jpg')\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e4ea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1962, 3488])\n",
      "tensor([[[ 79,  78,  80,  ..., 171, 174, 177],\n",
      "         [ 78,  78,  76,  ..., 174, 176, 175],\n",
      "         [ 81,  83,  82,  ..., 177, 178, 176],\n",
      "         ...,\n",
      "         [ 30,  29,  31,  ...,  47,  44,  44],\n",
      "         [ 32,  31,  33,  ...,  50,  46,  44],\n",
      "         [ 32,  31,  33,  ...,  54,  49,  45]],\n",
      "\n",
      "        [[116, 113, 115,  ..., 191, 194, 197],\n",
      "         [115, 115, 113,  ..., 195, 197, 196],\n",
      "         [117, 119, 117,  ..., 198, 199, 197],\n",
      "         ...,\n",
      "         [ 53,  52,  54,  ...,  66,  65,  67],\n",
      "         [ 53,  54,  56,  ...,  71,  67,  65],\n",
      "         [ 53,  54,  56,  ...,  75,  70,  66]],\n",
      "\n",
      "        [[169, 167, 169,  ..., 224, 227, 230],\n",
      "         [168, 168, 166,  ..., 226, 228, 227],\n",
      "         [169, 171, 171,  ..., 229, 230, 228],\n",
      "         ...,\n",
      "         [ 71,  70,  72,  ...,  83,  82,  83],\n",
      "         [ 72,  72,  74,  ...,  88,  84,  84],\n",
      "         [ 72,  72,  74,  ...,  92,  87,  85]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "img = torch.from_numpy(img)\n",
    "out = img.permute(2,0,1)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834fda53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 value is 1 and key is hello\n",
      "index 1 value is 2001 and key is year\n",
      "index 2 value is 4 and key is name\n"
     ]
    }
   ],
   "source": [
    "batch_num = 3\n",
    "\n",
    "test = {'hello':1,\"year\":2001,\"name\":4}\n",
    "\n",
    "for i, (k,v) in enumerate(test.items()):\n",
    "    print(f'index {i} value is {v} and key is {k}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf7ddf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.zeros(batch_num,3,256,256,dtype=torch.uint8)\n",
    "print(batch.shape)\n",
    "\n",
    "# print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f81c8305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daa3fa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porcessing batch completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = r'C:\\Users\\khesr\\Pictures\\Cities'\n",
    "\n",
    "prin = os.listdir(data_dir)\n",
    "\n",
    "# print(os.path.splitext(prin[0]))\n",
    "x = os.path.splitext(prin[0])\n",
    "\n",
    "names = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1].lower() in ('.jpg','.png')]\n",
    "\n",
    "#batch input image\n",
    "batch_size = len(names)\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.float32)\n",
    "\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((256, 256)),   # force all images to 256Ã—256\n",
    "    T.ToTensor()            # back to tensor [0,1]\n",
    "])\n",
    "\n",
    "# print(names)\n",
    "\n",
    "\n",
    "for i, filename in enumerate(names):\n",
    "    img = imageio.imread(os.path.join(data_dir,filename))\n",
    "    img_t = torch.from_numpy(img)\n",
    "    img_t = img_t.permute(2,0,1)[:3]\n",
    "    img_t = transform(img_t.byte())\n",
    "    batch[i] = img_t\n",
    "\n",
    "    \n",
    "\n",
    "print('porcessing batch completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "076e0381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0431, 0.0471, 0.0549,  ..., 0.4941, 0.5333, 0.5647],\n",
      "          [0.0431, 0.0471, 0.0549,  ..., 0.5098, 0.5647, 0.5961],\n",
      "          [0.0431, 0.0471, 0.0549,  ..., 0.5216, 0.5843, 0.6275],\n",
      "          ...,\n",
      "          [0.2471, 0.2510, 0.2510,  ..., 0.2784, 0.2706, 0.2392],\n",
      "          [0.2392, 0.2471, 0.2549,  ..., 0.2980, 0.2863, 0.2549],\n",
      "          [0.2431, 0.2510, 0.2549,  ..., 0.3137, 0.2980, 0.2745]],\n",
      "\n",
      "         [[0.0353, 0.0353, 0.0353,  ..., 0.4588, 0.5020, 0.5255],\n",
      "          [0.0353, 0.0353, 0.0353,  ..., 0.4706, 0.5255, 0.5529],\n",
      "          [0.0353, 0.0353, 0.0353,  ..., 0.4784, 0.5412, 0.5804],\n",
      "          ...,\n",
      "          [0.2824, 0.2784, 0.2745,  ..., 0.2627, 0.2510, 0.2196],\n",
      "          [0.2745, 0.2745, 0.2745,  ..., 0.2863, 0.2745, 0.2431],\n",
      "          [0.2784, 0.2745, 0.2706,  ..., 0.3020, 0.2863, 0.2627]],\n",
      "\n",
      "         [[0.0392, 0.0353, 0.0275,  ..., 0.4275, 0.4275, 0.4235],\n",
      "          [0.0392, 0.0353, 0.0275,  ..., 0.4471, 0.4627, 0.4588],\n",
      "          [0.0392, 0.0353, 0.0275,  ..., 0.4588, 0.4824, 0.4902],\n",
      "          ...,\n",
      "          [0.1608, 0.1569, 0.1569,  ..., 0.2353, 0.2275, 0.1961],\n",
      "          [0.1529, 0.1569, 0.1569,  ..., 0.2588, 0.2471, 0.2157],\n",
      "          [0.1647, 0.1647, 0.1647,  ..., 0.2745, 0.2588, 0.2353]]]])\n"
     ]
    }
   ],
   "source": [
    "print(batch[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11bf447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std completedd\n"
     ]
    }
   ],
   "source": [
    "# print(range(batch.shape[1])\n",
    "for c in range(batch.shape[1]):\n",
    "    mean = torch.mean(batch[:,c])\n",
    "    std = torch.std(batch[:,c])\n",
    "    batch[:,c] = (batch[:,c] - mean ) / std\n",
    "\n",
    "\n",
    "print('std completedd')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matrix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
